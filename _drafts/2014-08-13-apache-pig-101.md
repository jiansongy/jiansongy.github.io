---
layout: post
title: Apache Pig 101
comments: true
permalink: "apache-pig-101"
---

In [AN EARLIER BLOG POST!!!!](XXXXX), I introduced the basics of querying
data in SQL.  In this post, we will see how we can do similar sorts
of querying on large data sets stored on
[HDFS](http://en.wikipedia.org/wiki/Apache_Hadoop) using [Apache
Pig](https://pig.apache.org/).

## Hadoop, HDFS, MapReduce, and Apache Pig

Often, one has to deal with data sets so large that they cannot
fit on an individual machine.  To deal with data at this scale,
[Apache Hadoop](http://hadoop.apache.org/) provides the [Hadoop
Distributed File System
(HDFS)](http://en.wikipedia.org/wiki/Apache_Hadoop).  This produces
a distributed filesystem that automatically manages storing large
files across a cluster. In addition, HDFS provides a fault tolerance
mechanizsm to avoid typical problems of data loss.

On top of HDFS, Apache Hadoop provides a distributed data analysis
and data reduction programming language called
[MapReduce](http://wiki.apache.org/hadoop/MapReduce).  MapReduce
is parallizable and [fault
tolerant](http://developer.yahoo.com/hadoop/tutorial/module4.html#tolerence).
agains failures on individual machines.  On the other hand, it is
often cubmersome to write even simple algorithms as MapReduce jobs.

To improve developer productivity, Apache Pig was created as a
simpler data analysis langauge. Pig's langauge, called [Pig
Latin](http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html), is
very similar to SQL and provides all similar funcitonality in a
high-level data lanague. But under the hood, Pig creates a series
of MapReduce jobs which are run in success to perform the requried
data maniputation.

<!-- 
## Key Differences Between SQL and Pig

Although very similar, SQL and Pig have several practical differences:

* Simpler commands, written one after another.
* Conceptually, the code creates temporary tables, more similar to programming languages.
* Nested tables.
* More complicated data types like tuples, bags, etc. Why is this useful in the big data error.

No such thing as subquieries b/c you can procedurally
create tables.
-->

## Loading Data in Pig

In this post, I will introduce the main Pig operations using the
example recipes database from
[this post]({% post_url 2014-04-28-create-tables-sql %}).  
Although Pig is typically run on a Hadoop cluster across large data
sets, it is instructive to run work with these small tables in local
model.

We can read these tables in Pig by storing them in 
[CSV](http://en.wikipedia.org/wiki/Comma-separated_values) format:

```
$ cat recipes.csv
1,Tacos
2,Tomato Soup
3,Grilled Cheese

$ cat ingredients.csv
1,Beef,5
2,Lettuce,1
3,Tomatoes,2
4,Taco Shell,2
5,Cheese,3
6,Milk,1
7,Bread,2

$ cat recipe_ingredients.csv
1,1,1
1,2,2
1,3,2
1,4,3
1,5,1
2,3,2
2,6,1
3,5,1
3,7,2
```

You can find copies of these files [HERE!!!!](XXXXXXX).

You can launch Pig in local mode using the command:

```
$ pig -x local
```

First, we can load in the three tables with the `LOAD` command:

```
recipes = LOAD 'recipes.csv'
    USING PigStorage(',')
    AS (recipe_id:int, recipe_name:chararray,
        recipe_description:chararray);

ingredients = LOAD 'ingredients.csv'
    USING PigStorage(',')
    AS (ingredient_id:int, ingredient_name:chararray,
        ingredient_price:float);

recipe_ingredients = LOAD 'recipe_ingredients.csv'
    USING PigStorage(',')
    AS (recipe_id:int, ingredient_id:int,
        amount:int);
```

You will notice that unlike SQL, Pig does not force data to be
stored in any particular schema. Pig can read data in many different
formats. Out of the box, Pig provides several built in readers
including `PigStorage` for reading CSV data.

Now that we have loaded the data, we can easily look at the shema
of any of the tables:

```
DESCRIBE  recipes;
```

This returns

```
recipes: {recipe_id: int,recipe_name: chararray,recipe_description: chararray}
```

Similar, we can dump the values in a table with the command:

```
DUMP recipes
```

This returns the output:

```
(1,Tacos)
(2,Tomato Soup)
(3,Grilled Cheese)
```

This shows that the table contains:

| recipe_id |    recipe_name |
| --------- | -------------- |
|         0 |          Tacos |
|         1 |    Tomato Soup |
|         2 | Grilled Cheese |


## The FOREACH and FILTER Operator in Pig

Suppose we want to find the recipe_id for the recipe named "Tomato Soup".
To do this, we would first filter for the column we want
and in a second step project out the column we need:

```
soup_recipe = FILTER recipes
    BY recipe_name == 'Tomato Soup';
```

As expected, the `ingredient_names` contains:

| recipe_id |
| --------- |
|      XXXX |

## Joins in Pig

If we wanted to find the name of the ingredients in
the "Tomato Soup" recipe, we would need to
join the recipe_id table with the recipe_ingredients table
to get the ingredient IDs, and finally with the ingredient_names
table:

```
soup_recipe = FILTER recipes
    BY recipe_name == 'Tomato Soup';

soup_ingredients_joined = JOIN soup_recipe BY recipe_id, 
    recipe_ingredients BY recipe_id;

soup_ingredients_projected = FOREACH recipe_ingredients_by_name GENERATE
    recipe_ingredients::ingredient_id AS ingredient_id;

ingredient_names_joined = JOIN soup_ingredients_projected BY ingredient_id,
    ingredients BY ingredient_id;

ingredient_names = FOREACH ingredient_names_joined GENERATE
    ingredients::ingredient_name
```

As an aside, computing these tables is very costly, easier to
materialize denormalized tables. Somethign about how this is done
in batch mode.

## Blah

Joins in Pig are very similar to SQL.
When we join the `recipes` table with the `recipe_ingredients` table, we get:

```
recipe_ingredients_by_name = JOIN recipes BY recipe_id, recipe_ingredients BY recipe_id;
```

When we `DESCRIBE` the `recipe_ingredients_by_name` table, we see that the schema is

```
recipe_ingredients_by_name: {
    recipes::recipe_id: int,
    recipes::recipe_name: chararray,
    recipes::recipe_description: chararray,
    recipe_ingredients::recipe_id: int,
    recipe_ingredients::ingredient_id: int,
    recipe_ingredients::amount: int}
```

If we wanted to broadcast out only the columns we cared about, we could do so using the `FOREACH` command:

```
nicer_recipe_ingredients_by_name = FOREACH recipe_ingredients_by_name
    GENERATE
    recipes::recipe_name as recipe_name,
    recipes::recipe_id as recipe_id,
    recipes::recipe_description as recipe_description,
    recipe_ingredients::ingredient_id as ingredient_id,
    recipe_ingredients::amount as amount;
```

The table `nicer_recipe_ingredients_by_name` now contains:

|    recipe_name | recipe_id |        recipe_description | ingredient_id | amount |
| -------------- | --------- | ------------------------- | ------------- | ------ |
|          Tacos |         0 |        Mom's famous Tacos |             0 |      1 |
|          Tacos |         0 |        Mom's famous Tacos |             1 |      2 |
|          Tacos |         0 |        Mom's famous Tacos |             2 |      2 |
|          Tacos |         0 |        Mom's famous Tacos |             3 |      3 |
|          Tacos |         0 |        Mom's famous Tacos |             4 |      1 |
|    Tomato Soup |         1 |      Homemade Tomato soup |             2 |      2 |
|    Tomato Soup |         1 |      Homemade Tomato soup |             5 |      1 |
| Grilled Cheese |         2 | Delicious Cheese Sandwich |             4 |      1 |
| Grilled Cheese |         2 | Delicious Cheese Sandwich |             6 |      2 |

What is cool about Pig is that unlike SQL where more advanced
queries become more cumbersome requirng nested subquiries and mutiple joins, in Pig compliated quieries
just reuqire chaining the basic commands together.

If we wanted to find the ingredient names for
recipies which contain "Tomato Soup", all we have to do is
`FILTER` our table, `JOIN` it with the `ingredients` table,
and then broadcast out the column we want.

In Pig, this becomes

```
recipe_ingredients_filtered = FILTER nicer_recipe_ingredients_by_name
    BY recipe_name == 'Tomato Soup';

recipe_ingredients_recipe_name = JOIN
    recipe_ingredients_filtered BY ingredient_id,
    ingredients BY ingredient_id;

tomato_soup_ingredients = FOREACH recipe_ingredients_recipe_name
    GENERATE ingredient_name;
```

As expected, the table `tomato_soup_ingredients` table contains

| ingredient_name |
| --------------- |
|        Tomatoes |
|            Milk |



## The ORDER BY Operator in Pig

Suppose we wanted to sort the ingredients table
by price in descending order. In Pig we could use
the ORDER BY Operator:

```
ingredients_sorted = ORDER ingredients BY ingredient_price DESC;
```

The `ingredients_sorted` table contains:

| ingredient_id | ingredient_name | ingredient_price |
| ------------- | --------------- | ---------------- |
| 0             |            Beef |                5 |
| 4             |          Cheese |                3 |
| 2             |        Tomatoes |                2 |
| 3             |      Taco Shell |                2 |
| 6             |           Bread |                2 |
| 1             |         Lettuce |                1 |
| 5             |            Milk |                1 |

## The LIMIT Operator

Similarly, if we wanted to find only the most expensive ingredient,
we could

```
most_expensive = LIMIT ingredients_sorted 1;
```

The `most_expensive` table contains only the first row:

| ingredient_id | ingredient_name | ingredient_price |
| ------------- | --------------- | ---------------- |
| 0             |            Beef |                5 |

## Nested Data Structures in Pig

So far, everything we have seen about Pig probably seems fairly similar
to SQL. 
But one of the biggest ways in which Pig diverges from
SQL is that it allows for nested data structure.

For example, if we wanted, we could
define our recipes in a totally 
[denormalized](http://en.wikipedia.org/wiki/Denormalization)
data structure where the ingredients are nested within
the rows for each recipe.
commas separating items.

Despite having some obvious distadvantages, there are a
few advantages to having this denormalized data structure.

* Costly joins

To do that, we can define the file as:

```
$ cat recipes_denormalized.tsv
Tacos	{(Beef),(Lettuce),(Tomatoes),(Taco Shell),(Cheese)}
Tomato Soup		{(Tomatoes),(Milk)}
Grilled Cheese	{(Cheese),(Bread)}
```

I will mention that here that I switch from the CSV to TSV file format 
because pig gets confused between the commas separating items
in the bag from commas separating items. 
NOte that the charater between the recipe name
and the bag is a tab!

```
recipes_denormalized = LOAD 'recipes_denormalized.tsv'
    USING PigStorage('\t')
    AS (recipe:chararray, ingredients: {(name:chararray)});
```

When we `DESCRIBE` this table, we see that each row has a character array recipie
and a bag of ingredients:

```
recipes_denormalized: {
    recipe: chararray,
    ingredients: {
        (name: chararray)
    }
}
```

Similarly, when we `DUMP` this table:

```
(Tacos,{(Beef),(Lettuce),(Tomatoes),(Taco Shell),(Cheese)})
(Tomato Soup,{(Tomatoes),(Milk)})
(Grilled Cheese,{(Cheese),(Bread)})
```

Note that the tsv fileformat is wonkly, but Pig also
supports a more conventional JSON format for data.
To read the same data in JSON format, we could
define:


<!--
```
$ cat recipes_denormalized.json
{"recipe":"Tacos","ingredients":["Beef","Lettuce","Tomatoes","Taco Shell","Cheese"]}
{"recipe":"Tomato Soup","ingredients":["Tomatoes","Milk"]}
{"recipe":"Grilled Cheese","ingredients":["Cheese","Bread"]}
```
-->

```
$ cat recipes_denormalized.json
{"recipe":"Tacos",
 "ingredients": [
    {"name":"Beef"},
    {"name":"Lettuce"},
    {"name":"Tomatoes"},
    {"name":"Taco Shell"},
    {"name":"Cheese"}
]}
{"recipe":"Tomato Soup",
 "ingredients": [
    {"name":"Tomatoes"},
    {"name":"Milk"}
]}
{"recipe":"Grilled Cheese",
 "ingredients": [
    {"name":"Cheese"},
    {"name":"Bread"}
]}
```

And load the file using:

```
recipes_denormalized = LOAD 'recipes_denormalized.json' 
    USING JsonLoader('recipe:chararray, ingredients: {(name:chararray)}');
```

Note that because

```
recipes_denormalized = LOAD 'recipes_denormalized.json' USING JsonLoader()}');
```

...

```
STORE recipes_denormalized INTO 'recipes_denormalized.json' USING JsonStorage();
```


---

```
recipe_ingredients_denormalized = FOREACH recipes_denormalized
    GENERATE recipe,
    FLATTEN(ingredients.name) as ingredient;
DUMP recipe_ingredients_denormalized;
```

Creates:

```
(Tacos,Beef)
(Tacos,Lettuce)
(Tacos,Tomatoes)
(Tacos,Taco Shell)
(Tacos,Cheese)
(Tomato Soup,Tomatoes)
(Tomato Soup,Milk)
(Grilled Cheese,Cheese)
(Grilled Cheese,Bread)
```


## The GROUP BY Operator in Apache Pig

```
grouped_ingredients = GROUP recipe_ingredients 
    BY (recipe_id);
```

When we `DESCRIBE` the `grouped_ingredients` table:

```
grouped_ingredients: {
    group: int,
    recipe_ingredients: {
        (recipe_id: int,
         ingredient_id: int,
         amount: int)
    }
}
```

And when we `DUMP` the `grouped_ingredients` table:

```
(0,{(0,0,1),(0,1,2),(0,2,2),(0,3,3),(0,4,1)})
(1,{(1,2,2),(1,5,1)})
(2,{(2,4,1),(2,6,2)})
```

temp:

```
temp = FOREACH grouped_ingredients GENERATE
    group AS recipe_id,
    recipe_ingredients.ingredient_id AS ingredient_id;
```

When we `DUMP` temp


```
(0,{(0),(1),(2),(3),(4)})
(1,{(2),(5)})
(2,{(4),(6)})
```


```
STORE INTO 'temp2' USING PigStorage(',');
```

```
0,{(0),(1),(2),(3),(4)}
1,{(2),(5)}
2,{(4),(6)}
```

```
temp3 = LOAD 'temp2'
    USING PigStorage(',')
    AS (recipe_id:chararray, ingredient_id: {(name:chararray)});
```


## The DISTINCT Operator

## Set Operations: UNION and INTERSECTION

## Saving out tables to a file

XXX.

## Advanced Pig:

* Ternary expressions
* Skew `JOIN`
* replicated `JOIN`

## Links

...

{% include twitter_plug.html %}
